# Copyright (c) 2014-present Snowplow Analytics Ltd. All rights reserved.
#
# This software is made available by Snowplow Analytics, Ltd.,
# under the terms of the Snowplow Limited Use License Agreement, Version 1.1
# located at https://docs.snowplow.io/limited-use-license-1.1
# BY INSTALLING, DOWNLOADING, ACCESSING, USING OR DISTRIBUTING ANY PORTION
# OF THE SOFTWARE, YOU AGREE TO THE TERMS OF SUCH LICENSE AGREEMENT.

{

  "license" {
    "accept": "false"
    "accept": ${?ACCEPT_LIMITED_USE_LICENSE}
  }

  "gcpUserAgent": {
    "productName": "Snowplow OSS"
    "productName": ${?GCP_USER_AGENT_PRODUCT_NAME}
    "productVersion": "lake-loader"
  }

  "output": {
    "good": {
      "type": "Delta"
      "type": ${?packaging.output.good.type}

      "deltaTableProperties": {
        "delta.logRetentionDuration": "interval 1 days"
        "delta.dataSkippingStatsColumns": "load_tstamp,collector_tstamp,derived_tstamp,dvce_created_tstamp,true_tstamp"
        "delta.checkpointInterval": "50"
      }

      "icebergTableProperties": {
        "write.spark.accept-any-schema": "true"
        "write.object-storage.enabled": "true"
        "write.metadata.delete-after-commit.enabled": "true"
        "write.metadata.compression-codec": "gzip"
        "write.metadata.metrics.max-inferred-column-defaults": "0"
        "write.metadata.metrics.column.load_tstamp": "full"
        "write.metadata.metrics.column.collector_tstamp": "full"
        "write.metadata.metrics.column.derived_tstamp": "full"
        "write.metadata.metrics.column.dvce_created_tstamp": "full"
        "write.metadata.metrics.column.true_tstamp": "full"
        "commit.retry.num-retries": "20"
      }

      "icebergWriteOptions": {
        "merge-schema": "true"
        "check-ordering": "false"
        "distribution-mode": "none"
      }

      "catalog": {
        "type": "Hadoop"
        "options": {}
      }
    }
  }

  "inMemBatchBytes": 50000000
  "cpuParallelismFraction": 0.75
  "windowing": "5 minutes"
  "numEagerWindows": 1
  "spark": {
    "taskRetries": 3
    "conf": {
      "spark.ui.enabled": "false"
      "spark.local.dir": "/tmp" # This is the default but it's important for us
      "spark.serializer": "org.apache.spark.serializer.KryoSerializer"
      "spark.memory.fraction": "0.3" # Decreased from the Spark default to prevent OOMs
      "spark.sql.parquet.outputTimestampType": "TIMESTAMP_MICROS"
      "spark.sql.parquet.datetimeRebaseModeInWrite": "CORRECTED"
      "spark.memory.storageFraction": "0"
      "spark.databricks.delta.autoCompact.enabled": "false"
      "spark.scheduler.mode": "FAIR"
      "spark.sql.adaptive.enabled": "false" # False gives better performance on the type of shuffle done by Lake Loader
    }
    "gcpUserAgent": ${gcpUserAgent}
  }

  "retries": {
    "setupErrors": {
      "delay": "30 seconds"
    }
    "transientErrors": {
      "delay": "1 second"
      "attempts": 5
    }
  }

  "http": {
    "client": ${snowplow.defaults.http.client}
  }

  "skipSchemas": []
  "respectIgluNullability": true
  "exitOnMissingIgluSchema": true

  "monitoring": {
    "metrics": {
      "statsd": ${snowplow.defaults.statsd}
      "statsd": {
        "prefix": "snowplow.lakeloader"
      }
    }
    "webhook": ${snowplow.defaults.webhook}
    "sentry": {
      "tags": {
      }
    }
    "healthProbe": {
      "port": 8000
      "unhealthyLatency": "1 minute"
    }
  }

  "telemetry": ${snowplow.defaults.telemetry}
}
